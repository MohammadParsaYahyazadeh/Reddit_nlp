{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uam_iDrrZqYw",
        "outputId": "59c97190-97c2-4351-8202-0df9a169630b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/85.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hPackages installed (or already present).\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install -q keras-tuner shap category_encoders\n",
        "print('Packages installed (or already present).')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, math, gc\n",
        "import numpy as np, pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, roc_auc_score, log_loss, accuracy_score\n",
        "\n",
        "# Use on_bad_lines='skip' to skip the problematic line\n",
        "train = pd.read_csv('/content/xy_train.csv', on_bad_lines='skip')\n",
        "test  = pd.read_csv('/content/x_test.csv')\n",
        "sample_submission = pd.read_csv('/content/sample_submission.csv')\n",
        "\n",
        "# Auto-detect target\n",
        "target_candidates = [c for c in train.columns if c.lower() in ('target','label','y')]\n",
        "target = target_candidates[0] if target_candidates else train.columns[-1]\n",
        "y_series = train[target]\n",
        "if (y_series.dtype.kind in 'f' and y_series.nunique()>20):\n",
        "    problem_type='regression'\n",
        "elif y_series.nunique()==2:\n",
        "    problem_type='binary'\n",
        "elif 2<y_series.nunique()<=20:\n",
        "    problem_type='multiclass'\n",
        "else:\n",
        "    problem_type='regression'\n",
        "\n",
        "print('Target:', target)\n",
        "print('Problem type:', problem_type)\n",
        "print('train.shape', train.shape, 'test.shape', test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dehP12p5a4VQ",
        "outputId": "a0074f58-ef9f-482f-ed4f-252abdc20492"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: label\n",
            "Problem type: multiclass\n",
            "train.shape (48000, 3) test.shape (11955, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing: numeric impute + indicators, categorical top-K mapping, scaling\n",
        "num_cols = train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "if target in num_cols: num_cols.remove(target)\n",
        "cat_cols = [c for c in train.columns if c not in num_cols+[target] and train[c].dtype=='object']\n",
        "\n",
        "print('Numeric cols:', len(num_cols), 'Categorical cols:', len(cat_cols))\n",
        "\n",
        "train_tf = train.copy(); test_tf = test.copy()\n",
        "\n",
        "# Numeric imputation + indicator\n",
        "for c in num_cols:\n",
        "    med = train_tf[c].median()\n",
        "    train_tf[c].fillna(med, inplace=True)\n",
        "    test_tf[c].fillna(med, inplace=True)\n",
        "    train_tf[c + '_nan'] = train[c].isna().astype(int)\n",
        "    test_tf[c + '_nan'] = test[c].isna().astype(int)\n",
        "\n",
        "num_cols_ext = num_cols + [c + '_nan' for c in num_cols]\n",
        "\n",
        "# Categorical: top-K cap and mapping\n",
        "TOPK = 10000\n",
        "cat_maps = {}\n",
        "cat_cardinalities = {}\n",
        "for c in cat_cols:\n",
        "    train_tf[c] = train_tf[c].fillna('___missing___').astype(str)\n",
        "    test_tf[c]  = test_tf[c].fillna('___missing___').astype(str)\n",
        "    vc = train_tf[c].value_counts()\n",
        "    if len(vc) > TOPK:\n",
        "        keep = set(vc.index[:TOPK])\n",
        "        train_tf[c] = train_tf[c].apply(lambda x: x if x in keep else '__other__')\n",
        "        test_tf[c]  = test_tf[c].apply(lambda x: x if x in keep else '__other__')\n",
        "        vc = train_tf[c].value_counts()\n",
        "    uniq = list(vc.index)\n",
        "    mapping = {k:i+1 for i,k in enumerate(uniq)}  # reserve 0 for unknown\n",
        "    mapping['__other__'] = 0\n",
        "    cat_maps[c] = mapping\n",
        "    cat_cardinalities[c] = max(1, len(mapping))\n",
        "\n",
        "# Apply mapping arrays\n",
        "if len(cat_cols) > 0:\n",
        "    X_cat_train = np.stack([train_tf[c].map(lambda x: cat_maps[c].get(x,0)).astype(np.int32).values for c in cat_cols], axis=1)\n",
        "    X_cat_test  = np.stack([test_tf[c].map(lambda x: cat_maps[c].get(x,0)).astype(np.int32).values for c in cat_cols], axis=1)\n",
        "else:\n",
        "    X_cat_train = np.zeros((len(train_tf),0), dtype=np.int32)\n",
        "    X_cat_test  = np.zeros((len(test_tf),0), dtype=np.int32)\n",
        "\n",
        "# Scale numeric features\n",
        "scaler = StandardScaler()\n",
        "X_num_train = scaler.fit_transform(train_tf[num_cols_ext].astype(float).values)\n",
        "X_num_test  = scaler.transform(test_tf[num_cols_ext].astype(float).values)\n",
        "\n",
        "y = train_tf[target].values\n",
        "\n",
        "print('Shapes -> X_num:', X_num_train.shape, 'X_cat:', X_cat_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfbL76Fzb2ih",
        "outputId": "24e77f70-554a-4a6d-bb92-4eca41f84e85"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numeric cols: 1 Categorical cols: 1\n",
            "Shapes -> X_num: (48000, 2) X_cat: (48000, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4186526252.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  train_tf[c].fillna(med, inplace=True)\n",
            "/tmp/ipython-input-4186526252.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  test_tf[c].fillna(med, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Leakage-safe target encoding (CV-based)\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "\n",
        "def target_encode_cv(train_df, test_df, col, target_col, n_splits=5, problem_type='regression', smoothing=0.3):\n",
        "    te_vals = np.zeros(len(train_df))\n",
        "    global_mean = train_df[target_col].mean()\n",
        "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42) if (problem_type!='regression' and train_df[target_col].nunique()>1) else KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "    for tr_idx, val_idx in kf.split(train_df, train_df[target_col] if problem_type!='regression' else None):\n",
        "        grp = train_df.iloc[tr_idx].groupby(col)[target_col].agg(['mean','count'])\n",
        "        smooth = (grp['count'] * grp['mean'] + smoothing * global_mean) / (grp['count'] + smoothing)\n",
        "        mapping = smooth.to_dict()\n",
        "        te_vals[val_idx] = train_df.iloc[val_idx][col].map(mapping).fillna(global_mean).values\n",
        "    full_grp = train_df.groupby(col)[target_col].agg(['mean','count'])\n",
        "    smooth_full = (full_grp['count'] * full_grp['mean'] + smoothing * global_mean) / (full_grp['count'] + smoothing)\n",
        "    test_enc = test_df[col].map(smooth_full.to_dict()).fillna(global_mean).values\n",
        "    return te_vals, test_enc\n",
        "\n",
        "# Toggle target encoding here (limit number of columns to avoid slowdown)\n",
        "apply_te = True\n",
        "if apply_te and len(cat_cols) > 0:\n",
        "    te_cols = cat_cols[:2]  # adjust as needed\n",
        "    for c in te_cols:\n",
        "        print('Applying TE to', c)\n",
        "        tr_enc, te_enc = target_encode_cv(train_tf, test_tf, c, target, n_splits=5, problem_type=problem_type)\n",
        "        X_num_train = np.hstack([X_num_train, tr_enc.reshape(-1,1)])\n",
        "        X_num_test  = np.hstack([X_num_test, te_enc.reshape(-1,1)])\n",
        "    print('New numeric shape:', X_num_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a_h7_dJcSsf",
        "outputId": "55868bda-5818-4919-c028-c9da99d16388"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying TE to text\n",
            "New numeric shape: (48000, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tf.data dataset helpers with numeric noise augmentation\n",
        "import tensorflow as tf\n",
        "\n",
        "def make_dataset(X_num, X_cat, y=None, batch_size=256, shuffle=False, augment=False, noise_std=0.01):\n",
        "    ds_num = tf.data.Dataset.from_tensor_slices(X_num.astype('float32'))\n",
        "    ds_cat = tf.data.Dataset.from_tensor_slices(X_cat.astype('int32'))\n",
        "    if y is not None:\n",
        "        ds_y = tf.data.Dataset.from_tensor_slices(y)\n",
        "        ds = tf.data.Dataset.zip((ds_num, ds_cat, ds_y))\n",
        "    else:\n",
        "        ds = tf.data.Dataset.zip((ds_num, ds_cat))\n",
        "    if shuffle and y is not None:\n",
        "        ds = ds.shuffle(buffer_size=len(X_num), seed=42)\n",
        "    def pack(num, cat, lab=None):\n",
        "        if y is not None:\n",
        "            if augment:\n",
        "                num = num + tf.random.normal(tf.shape(num), stddev=noise_std)\n",
        "            return ({'num': num, 'cat': cat}, lab)\n",
        "        else:\n",
        "            return ({'num': num, 'cat': cat})\n",
        "    if y is not None:\n",
        "        ds = ds.map(pack, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    else:\n",
        "        ds = ds.map(lambda num,cat: ({'num': num, 'cat': cat}), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "    return ds"
      ],
      "metadata": {
        "id": "6DF6odKccX05"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Advanced model builder: embeddings + transformer blocks + MLP head\n",
        "# import tensorflow_addons as tfa # Removed tensorflow_addons import\n",
        "\n",
        "def transformer_block(x, num_heads=4, key_dim=32, ff_dim=128, dropout=0.1, l2_reg=1e-5):\n",
        "    attn = layers.MultiHeadAttention(num_heads=num_heads, key_dim=key_dim)(x, x)\n",
        "    attn = layers.Dropout(dropout)(attn)\n",
        "    out1 = layers.LayerNormalization(epsilon=1e-6)(x + attn)\n",
        "    ff = layers.Dense(ff_dim, activation='relu', kernel_regularizer=keras.regularizers.l2(l2_reg))(out1)\n",
        "    ff = layers.Dense(out1.shape[-1], kernel_regularizer=keras.regularizers.l2(l2_reg))(ff)\n",
        "    ff = layers.Dropout(dropout)(ff)\n",
        "    return layers.LayerNormalization(epsilon=1e-6)(out1 + ff)\n",
        "\n",
        "def build_advanced_model(cat_cardinalities, num_input_dim,\n",
        "                         emb_dropout=0.12, embed_dim_rule='sqrt',\n",
        "                         n_transformer_blocks=2, num_heads=4, key_dim=32, ff_dim=128,\n",
        "                         mlp_units=[512,256], mlp_dropout=0.2, l2_reg=1e-5):\n",
        "    num_in = layers.Input(shape=(num_input_dim,), name='num', dtype=tf.float32)\n",
        "    cat_in = layers.Input(shape=(len(cat_cardinalities),), name='cat', dtype=tf.int32)\n",
        "\n",
        "    embeds = []\n",
        "    for i,(col,card) in enumerate(cat_cardinalities.items()):\n",
        "        if embed_dim_rule == 'sqrt':\n",
        "            emb_dim = max(4, int(min(50, math.sqrt(card))))\n",
        "        elif isinstance(embed_dim_rule, int):\n",
        "            emb_dim = embed_dim_rule\n",
        "        else:\n",
        "            emb_dim = max(4, int(min(50, math.sqrt(card))))\n",
        "        slice_i = layers.Lambda(lambda x, i=i: x[:, i:i+1])(cat_in)\n",
        "        e = layers.Embedding(input_dim=card+1, output_dim=emb_dim,\n",
        "                             embeddings_regularizer=keras.regularizers.l2(l2_reg))(slice_i)\n",
        "        e = layers.Reshape((emb_dim,))(e)\n",
        "        embeds.append(e)\n",
        "    if len(embeds) > 0:\n",
        "        cat_embed = layers.Concatenate()(embeds)\n",
        "        cat_embed = layers.Dropout(emb_dropout)(cat_embed)\n",
        "    else:\n",
        "        cat_embed = None\n",
        "\n",
        "    num_branch = layers.LayerNormalization()(num_in)\n",
        "    num_branch = layers.Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(l2_reg))(num_branch)\n",
        "    num_branch = layers.Dropout(mlp_dropout)(num_branch)\n",
        "\n",
        "    if cat_embed is not None:\n",
        "        num_token = layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2(l2_reg))(num_branch)\n",
        "        split_tokens = []\n",
        "        total_dim = int(cat_embed.shape[-1])\n",
        "        n_cat = len(embeds)\n",
        "        per = max(1, total_dim // n_cat)\n",
        "        for i in range(n_cat):\n",
        "            start = i*per\n",
        "            end = start + per if i < n_cat-1 else total_dim\n",
        "            token = layers.Lambda(lambda x, s=start, e=end: x[:, s:e])(cat_embed)\n",
        "            token = layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2(l2_reg))(token)\n",
        "            split_tokens.append(layers.Reshape((1, int(token.shape[-1])))(token))\n",
        "        tokens = [layers.Reshape((1, int(num_token.shape[-1])))(num_token)] + split_tokens\n",
        "        seq = layers.Concatenate(axis=1)(tokens)\n",
        "    else:\n",
        "        seq = layers.Reshape((1, int(num_branch.shape[-1])))(num_branch)\n",
        "\n",
        "    x = seq\n",
        "    for _ in range(n_transformer_blocks):\n",
        "        x = transformer_block(x, num_heads=num_heads, key_dim=key_dim, ff_dim=ff_dim, dropout=mlp_dropout, l2_reg=l2_reg)\n",
        "\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "    if cat_embed is not None:\n",
        "        h = layers.Concatenate()([x, num_branch, cat_embed])\n",
        "    else:\n",
        "        h = layers.Concatenate()([x, num_branch])\n",
        "\n",
        "    for u in mlp_units:\n",
        "        h = layers.Dense(u, activation='relu', kernel_regularizer=keras.regularizers.l2(l2_reg))(h)\n",
        "        h = layers.LayerNormalization()(h)\n",
        "        h = layers.Dropout(mlp_dropout)(h)\n",
        "\n",
        "    if problem_type == 'regression':\n",
        "        out = layers.Dense(1, dtype='float32', name='out')(h)\n",
        "        loss = 'mse'; metrics=[keras.metrics.RootMeanSquaredError()]\n",
        "    elif problem_type == 'binary':\n",
        "        out = layers.Dense(1, activation='sigmoid', dtype='float32', name='out')(h)\n",
        "        loss = 'binary_crossentropy'; metrics=[keras.metrics.AUC()]\n",
        "    else:\n",
        "        n_classes = int(np.unique(y).shape[0])\n",
        "        out = layers.Dense(n_classes, activation='softmax', dtype='float32', name='out')(h)\n",
        "        loss = 'sparse_categorical_crossentropy'; metrics=['sparse_categorical_accuracy']\n",
        "\n",
        "    model = keras.Model(inputs=[num_in, cat_in], outputs=out)\n",
        "    # try:\n",
        "    #     opt = tfa.optimizers.AdamW(learning_rate=1e-3, weight_decay=1e-5)\n",
        "    # except Exception:\n",
        "    opt = keras.optimizers.Adam(learning_rate=1e-3)\n",
        "    model.compile(optimizer=opt, loss=loss, metrics=metrics)\n",
        "    return model"
      ],
      "metadata": {
        "id": "EnrlsfsIciBZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick demo build to ensure model compiles\n",
        "model = build_advanced_model(cat_cardinalities, X_num_train.shape[1],\n",
        "                             emb_dropout=0.12, embed_dim_rule='sqrt',\n",
        "                             n_transformer_blocks=1, num_heads=2, key_dim=32, ff_dim=64,\n",
        "                             mlp_units=[256,128], mlp_dropout=0.15, l2_reg=1e-5)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4dcQWr9YcrKi",
        "outputId": "f60aa4d4-9ec6-4c29-ce2d-65154e54b1f5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ cat (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda (\u001b[38;5;33mLambda\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ cat[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)     │    \u001b[38;5;34m500,100\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ num (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape (\u001b[38;5;33mReshape\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │          \u001b[38;5;34m6\u001b[0m │ num[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m512\u001b[0m │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda_1 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m3,264\u001b[0m │ lambda_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_2 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ reshape_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ reshape_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │     \u001b[38;5;34m16,640\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m128\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │      \u001b[38;5;34m4,160\u001b[0m │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │      \u001b[38;5;34m4,160\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│                     │                   │            │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m128\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m242\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                     │                   │            │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m62,208\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │        \u001b[38;5;34m512\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m256\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ out (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │        \u001b[38;5;34m387\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ cat (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ cat[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">500,100</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ num (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │ num[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,264</span> │ lambda_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ reshape_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ reshape_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│                     │                   │            │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">242</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                     │                   │            │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">62,208</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m633,613\u001b[0m (2.42 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">633,613</span> (2.42 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m633,613\u001b[0m (2.42 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">633,613</span> (2.42 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick K-Fold smoke test (small folds/epochs)\n",
        "N_FOLDS = 3\n",
        "BATCH_SIZE = 256\n",
        "EPOCHS = 8\n",
        "\n",
        "kf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42) if (problem_type!='regression') else KFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
        "\n",
        "oof = np.zeros((len(X_num_train),) if problem_type!='multiclass' else (len(X_num_train), int(np.unique(y).shape[0])))\n",
        "test_pred = np.zeros((len(X_num_test),) if problem_type!='multiclass' else (len(X_num_test), int(np.unique(y).shape[0])))\n",
        "\n",
        "for fold, (tr, val) in enumerate(kf.split(X_num_train, y if problem_type!='regression' else None)):\n",
        "    print('\\nFold', fold+1)\n",
        "    Xn_tr, Xn_val = X_num_train[tr], X_num_train[val]\n",
        "    Xc_tr, Xc_val = X_cat_train[tr], X_cat_train[val]\n",
        "    y_tr, y_val = y[tr], y[val]\n",
        "\n",
        "    ds_tr = make_dataset(Xn_tr, Xc_tr, y_tr, batch_size=BATCH_SIZE, shuffle=True, augment=True)\n",
        "    ds_val = make_dataset(Xn_val, Xc_val, y_val, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    model = build_advanced_model(cat_cardinalities, X_num_train.shape[1],\n",
        "                                 emb_dropout=0.12, embed_dim_rule='sqrt',\n",
        "                                 n_transformer_blocks=1, num_heads=2, key_dim=32, ff_dim=64,\n",
        "                                 mlp_units=[256,128], mlp_dropout=0.15, l2_reg=1e-5)\n",
        "    ckpt = f'quick_fold_{fold+1}.h5'\n",
        "    callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=1),\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=2, factor=0.5, verbose=1),\n",
        "        tf.keras.callbacks.ModelCheckpoint(ckpt, save_best_only=True, monitor='val_loss', verbose=0)\n",
        "    ]\n",
        "    history = model.fit(ds_tr, validation_data=ds_val, epochs=EPOCHS, callbacks=callbacks, verbose=2)\n",
        "    val_preds = model.predict(make_dataset(Xn_val, Xc_val, y=None, batch_size=512), verbose=0)\n",
        "    if problem_type == 'multiclass':\n",
        "        oof[val] = val_preds\n",
        "    else:\n",
        "        oof[val] = val_preds.reshape(-1)\n",
        "    test_fold = model.predict(make_dataset(X_num_test, X_cat_test, y=None, batch_size=512), verbose=0)\n",
        "    if problem_type == 'multiclass':\n",
        "        test_pred += test_fold / N_FOLDS\n",
        "    else:\n",
        "        test_pred += test_fold.reshape(-1) / N_FOLDS\n",
        "\n",
        "if problem_type == 'regression':\n",
        "    print('Quick CV RMSE:', mean_squared_error(y, oof, squared=False))\n",
        "elif problem_type == 'binary':\n",
        "    print('Quick CV AUC:', roc_auc_score(y, oof))\n",
        "else:\n",
        "    print('Quick CV logloss:', log_loss(y, oof), 'acc:', accuracy_score(y, np.argmax(oof, axis=1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7l8xh5KdGWj",
        "outputId": "64dbba1f-5db5-40eb-f830-d75578a4080a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 1\n",
            "Epoch 1/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "125/125 - 19s - 156ms/step - loss: 0.7735 - sparse_categorical_accuracy: 0.5095 - val_loss: 0.7275 - val_sparse_categorical_accuracy: 0.4669 - learning_rate: 1.0000e-03\n",
            "Epoch 2/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "125/125 - 6s - 49ms/step - loss: 0.7290 - sparse_categorical_accuracy: 0.5235 - val_loss: 0.7218 - val_sparse_categorical_accuracy: 0.5376 - learning_rate: 1.0000e-03\n",
            "Epoch 3/8\n",
            "125/125 - 10s - 82ms/step - loss: 0.6460 - sparse_categorical_accuracy: 0.5932 - val_loss: 0.7646 - val_sparse_categorical_accuracy: 0.5394 - learning_rate: 1.0000e-03\n",
            "Epoch 4/8\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "125/125 - 8s - 62ms/step - loss: 0.5817 - sparse_categorical_accuracy: 0.6224 - val_loss: 1.0857 - val_sparse_categorical_accuracy: 0.5394 - learning_rate: 1.0000e-03\n",
            "Epoch 5/8\n",
            "125/125 - 9s - 69ms/step - loss: 0.5760 - sparse_categorical_accuracy: 0.6274 - val_loss: 1.0787 - val_sparse_categorical_accuracy: 0.4283 - learning_rate: 5.0000e-04\n",
            "Epoch 5: early stopping\n",
            "Restoring model weights from the end of the best epoch: 2.\n",
            "\n",
            "Fold 2\n",
            "Epoch 1/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "125/125 - 17s - 136ms/step - loss: 0.7868 - sparse_categorical_accuracy: 0.5081 - val_loss: 0.7265 - val_sparse_categorical_accuracy: 0.5375 - learning_rate: 1.0000e-03\n",
            "Epoch 2/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "125/125 - 6s - 50ms/step - loss: 0.7326 - sparse_categorical_accuracy: 0.5163 - val_loss: 0.7209 - val_sparse_categorical_accuracy: 0.5375 - learning_rate: 1.0000e-03\n",
            "Epoch 3/8\n",
            "125/125 - 10s - 83ms/step - loss: 0.7181 - sparse_categorical_accuracy: 0.5358 - val_loss: 0.7443 - val_sparse_categorical_accuracy: 0.5209 - learning_rate: 1.0000e-03\n",
            "Epoch 4/8\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "125/125 - 8s - 62ms/step - loss: 0.6085 - sparse_categorical_accuracy: 0.6095 - val_loss: 0.8509 - val_sparse_categorical_accuracy: 0.5400 - learning_rate: 1.0000e-03\n",
            "Epoch 5/8\n",
            "125/125 - 6s - 49ms/step - loss: 0.5790 - sparse_categorical_accuracy: 0.6252 - val_loss: 0.8825 - val_sparse_categorical_accuracy: 0.5400 - learning_rate: 5.0000e-04\n",
            "Epoch 5: early stopping\n",
            "Restoring model weights from the end of the best epoch: 2.\n",
            "\n",
            "Fold 3\n",
            "Epoch 1/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "125/125 - 15s - 120ms/step - loss: 0.7914 - sparse_categorical_accuracy: 0.5084 - val_loss: 0.7210 - val_sparse_categorical_accuracy: 0.5374 - learning_rate: 1.0000e-03\n",
            "Epoch 2/8\n",
            "125/125 - 10s - 78ms/step - loss: 0.7312 - sparse_categorical_accuracy: 0.5174 - val_loss: 0.7211 - val_sparse_categorical_accuracy: 0.5374 - learning_rate: 1.0000e-03\n",
            "Epoch 3/8\n",
            "125/125 - 8s - 66ms/step - loss: 0.6888 - sparse_categorical_accuracy: 0.5650 - val_loss: 0.7467 - val_sparse_categorical_accuracy: 0.5236 - learning_rate: 1.0000e-03\n",
            "Epoch 4/8\n",
            "125/125 - 6s - 49ms/step - loss: 0.5915 - sparse_categorical_accuracy: 0.6157 - val_loss: 0.8736 - val_sparse_categorical_accuracy: 0.5238 - learning_rate: 5.0000e-04\n",
            "Epoch 4: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "Quick CV logloss: 0.7136496808206424 acc: 0.5375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Keras-Tuner (small budget example)\n",
        "import keras_tuner as kt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class AdvancedHyperModel(kt.HyperModel):\n",
        "    def build(self, hp):\n",
        "        n_blocks = hp.Int('n_blocks', 1, 2)\n",
        "        heads = hp.Choice('heads', [2,4])\n",
        "        ff_dim = hp.Choice('ff_dim', [64,128])\n",
        "        mlp1 = hp.Int('mlp1', 128, 384, step=128)\n",
        "        drop = hp.Float('drop', 0.0, 0.3, step=0.05)\n",
        "        return build_advanced_model(cat_cardinalities, X_num_train.shape[1],\n",
        "                                    emb_dropout=hp.Float('emb_drop', 0.0, 0.2),\n",
        "                                    n_transformer_blocks=n_blocks, num_heads=heads, key_dim=32, ff_dim=ff_dim,\n",
        "                                    mlp_units=[mlp1, max(64, mlp1//2)], mlp_dropout=drop, l2_reg=1e-5)\n",
        "\n",
        "tuner = kt.RandomSearch(AdvancedHyperModel(), objective='val_loss', max_trials=4, executions_per_trial=1, directory='kt_dir', project_name='tf_adv')\n",
        "SUBSET = min(5000, len(X_num_train))\n",
        "\n",
        "# Split data into training and validation sets\n",
        "Xn_train_sub, Xn_val_sub, Xc_train_sub, Xc_val_sub, y_train_sub, y_val_sub = train_test_split(\n",
        "    X_num_train[:SUBSET], X_cat_train[:SUBSET], y[:SUBSET], test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Create tf.data datasets for training and validation\n",
        "ds_tr = make_dataset(Xn_train_sub, Xc_train_sub, y_train_sub, shuffle=True)\n",
        "ds_val = make_dataset(Xn_val_sub, Xc_val_sub, y_val_sub, shuffle=False)\n",
        "\n",
        "\n",
        "tuner.search(ds_tr, epochs=6, validation_data=ds_val)\n",
        "print('Best hyperparameters:', tuner.get_best_hyperparameters(1)[0].values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmHJZ19jdMRF",
        "outputId": "27c4c162-44c6-4385-ce82-b9384796139d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 4 Complete [00h 00m 23s]\n",
            "val_loss: 0.7056900262832642\n",
            "\n",
            "Best val_loss So Far: 0.7050557732582092\n",
            "Total elapsed time: 00h 01m 34s\n",
            "Best hyperparameters: {'n_blocks': 2, 'heads': 4, 'ff_dim': 64, 'mlp1': 384, 'drop': 0.15000000000000002, 'emb_drop': 0.19439959418277064}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Final training using tuner results (if available), otherwise defaults\n",
        "try:\n",
        "    best_hp = tuner.get_best_hyperparameters(1)[0]\n",
        "    n_blocks = best_hp.get('n_blocks'); heads = best_hp.get('heads'); ff_dim = best_hp.get('ff_dim')\n",
        "    mlp1 = best_hp.get('mlp1'); drop = best_hp.get('drop'); emb_drop = best_hp.get('emb_drop')\n",
        "    mlp_units = [mlp1, max(64, mlp1//2)]\n",
        "    n_transformer_blocks = n_blocks; num_heads = heads; key_dim = 32; mlp_dropout = drop; emb_dropout = emb_drop\n",
        "    print('Using tuner hyperparams:', best_hp.values)\n",
        "except Exception as e:\n",
        "    print('No tuner results, using defaults'); n_transformer_blocks=2; num_heads=4; key_dim=32; ff_dim=128; mlp_units=[512,256]; mlp_dropout=0.2; emb_dropout=0.12\n",
        "\n",
        "N_FOLDS = 5\n",
        "BATCH_SIZE = 256\n",
        "EPOCHS = 50\n",
        "kf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42) if (problem_type!='regression') else KFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
        "\n",
        "oof_final = np.zeros((len(X_num_train),) if problem_type!='multiclass' else (len(X_num_train), int(np.unique(y).shape[0])))\n",
        "test_final = np.zeros((len(X_num_test),) if problem_type!='multiclass' else (len(X_num_test), int(np.unique(y).shape[0])))\n",
        "\n",
        "for fold, (tr, val) in enumerate(kf.split(X_num_train, y if problem_type!='regression' else None)):\n",
        "    print('\\nFinal Fold', fold+1)\n",
        "    Xn_tr, Xn_val = X_num_train[tr], X_num_train[val]\n",
        "    Xc_tr, Xc_val = X_cat_train[tr], X_cat_train[val]\n",
        "    y_tr, y_val = y[tr], y[val]\n",
        "\n",
        "    ds_tr = make_dataset(Xn_tr, Xc_tr, y_tr, batch_size=BATCH_SIZE, shuffle=True, augment=True)\n",
        "    ds_val = make_dataset(Xn_val, Xc_val, y_val, batch_size=BATCH_SIZE, shuffle=False)\n",
        "    ds_test = make_dataset(X_num_test, X_cat_test, y=None, batch_size=512, shuffle=False)\n",
        "\n",
        "    model = build_advanced_model(cat_cardinalities, X_num_train.shape[1],\n",
        "                                 emb_dropout=emb_dropout, embed_dim_rule='sqrt',\n",
        "                                 n_transformer_blocks=n_transformer_blocks, num_heads=num_heads, key_dim=key_dim, ff_dim=ff_dim,\n",
        "                                 mlp_units=mlp_units, mlp_dropout=mlp_dropout, l2_reg=1e-5)\n",
        "\n",
        "    ckpt = f'final_model_fold_{fold+1}.h5'\n",
        "    callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True, verbose=1),\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.5, verbose=1),\n",
        "        tf.keras.callbacks.ModelCheckpoint(ckpt, save_best_only=True, monitor='val_loss', verbose=0)\n",
        "    ]\n",
        "\n",
        "    history = model.fit(ds_tr, validation_data=ds_val, epochs=EPOCHS, callbacks=callbacks, verbose=2)\n",
        "    val_preds = model.predict(make_dataset(Xn_val, Xc_val, y=None, batch_size=512), verbose=0)\n",
        "    if problem_type == 'multiclass':\n",
        "        oof_final[val] = val_preds\n",
        "    else:\n",
        "        oof_final[val] = val_preds.reshape(-1)\n",
        "    test_fold = model.predict(ds_test, verbose=0)\n",
        "    if problem_type == 'multiclass':\n",
        "        test_final += test_fold / N_FOLDS\n",
        "    else:\n",
        "        test_final += test_fold.reshape(-1) / N_FOLDS\n",
        "\n",
        "if problem_type == 'regression':\n",
        "    print('\\nFinal CV RMSE:', mean_squared_error(y, oof_final, squared=False))\n",
        "elif problem_type == 'binary':\n",
        "    print('\\nFinal CV AUC:', roc_auc_score(y, oof_final))\n",
        "else:\n",
        "    print('\\nFinal CV logloss:', log_loss(y, oof_final), 'CV acc:', accuracy_score(y, np.argmax(oof_final, axis=1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqnYhTDxd1qJ",
        "outputId": "bb0443d0-614e-494d-e68c-36fa99f02f1d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using tuner hyperparams: {'n_blocks': 2, 'heads': 4, 'ff_dim': 64, 'mlp1': 384, 'drop': 0.15000000000000002, 'emb_drop': 0.19439959418277064}\n",
            "\n",
            "Final Fold 1\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "150/150 - 31s - 210ms/step - loss: 0.7723 - sparse_categorical_accuracy: 0.5117 - val_loss: 0.7228 - val_sparse_categorical_accuracy: 0.5375 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "150/150 - 16s - 108ms/step - loss: 0.7315 - sparse_categorical_accuracy: 0.5172 - val_loss: 0.7228 - val_sparse_categorical_accuracy: 0.5375 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "150/150 - 15s - 102ms/step - loss: 0.6859 - sparse_categorical_accuracy: 0.5646 - val_loss: 0.7344 - val_sparse_categorical_accuracy: 0.5279 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "150/150 - 21s - 140ms/step - loss: 0.5882 - sparse_categorical_accuracy: 0.6226 - val_loss: 0.7214 - val_sparse_categorical_accuracy: 0.5392 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "150/150 - 20s - 135ms/step - loss: 0.5802 - sparse_categorical_accuracy: 0.6233 - val_loss: 0.9271 - val_sparse_categorical_accuracy: 0.5403 - learning_rate: 1.0000e-03\n",
            "Epoch 6/50\n",
            "150/150 - 16s - 104ms/step - loss: 0.5774 - sparse_categorical_accuracy: 0.6237 - val_loss: 0.8025 - val_sparse_categorical_accuracy: 0.5403 - learning_rate: 1.0000e-03\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "150/150 - 21s - 140ms/step - loss: 0.5761 - sparse_categorical_accuracy: 0.6258 - val_loss: 1.0918 - val_sparse_categorical_accuracy: 0.5403 - learning_rate: 1.0000e-03\n",
            "Epoch 8/50\n",
            "150/150 - 20s - 130ms/step - loss: 0.5741 - sparse_categorical_accuracy: 0.6271 - val_loss: 0.8641 - val_sparse_categorical_accuracy: 0.5403 - learning_rate: 5.0000e-04\n",
            "Epoch 9/50\n",
            "150/150 - 21s - 139ms/step - loss: 0.5737 - sparse_categorical_accuracy: 0.6298 - val_loss: 0.8946 - val_sparse_categorical_accuracy: 0.5403 - learning_rate: 5.0000e-04\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "150/150 - 15s - 101ms/step - loss: 0.5728 - sparse_categorical_accuracy: 0.6304 - val_loss: 0.8428 - val_sparse_categorical_accuracy: 0.5407 - learning_rate: 5.0000e-04\n",
            "Epoch 11/50\n",
            "150/150 - 15s - 101ms/step - loss: 0.5722 - sparse_categorical_accuracy: 0.6311 - val_loss: 0.9613 - val_sparse_categorical_accuracy: 0.5403 - learning_rate: 2.5000e-04\n",
            "Epoch 12/50\n",
            "150/150 - 16s - 105ms/step - loss: 0.5729 - sparse_categorical_accuracy: 0.6303 - val_loss: 0.9185 - val_sparse_categorical_accuracy: 0.5403 - learning_rate: 2.5000e-04\n",
            "Epoch 12: early stopping\n",
            "Restoring model weights from the end of the best epoch: 4.\n",
            "\n",
            "Final Fold 2\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "150/150 - 29s - 192ms/step - loss: 0.7713 - sparse_categorical_accuracy: 0.5084 - val_loss: 0.7238 - val_sparse_categorical_accuracy: 0.5383 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "Epoch 3/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "150/150 - 16s - 104ms/step - loss: 0.7271 - sparse_categorical_accuracy: 0.5242 - val_loss: 0.7228 - val_sparse_categorical_accuracy: 0.5392 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "150/150 - 17s - 113ms/step - loss: 0.6122 - sparse_categorical_accuracy: 0.6093 - val_loss: 0.7223 - val_sparse_categorical_accuracy: 0.5395 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "150/150 - 19s - 128ms/step - loss: 0.5813 - sparse_categorical_accuracy: 0.6265 - val_loss: 1.1390 - val_sparse_categorical_accuracy: 0.5158 - learning_rate: 1.0000e-03\n",
            "Epoch 6/50\n",
            "150/150 - 15s - 101ms/step - loss: 0.5767 - sparse_categorical_accuracy: 0.6292 - val_loss: 0.7278 - val_sparse_categorical_accuracy: 0.5385 - learning_rate: 1.0000e-03\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "150/150 - 21s - 140ms/step - loss: 0.5754 - sparse_categorical_accuracy: 0.6287 - val_loss: 1.4373 - val_sparse_categorical_accuracy: 0.5158 - learning_rate: 1.0000e-03\n",
            "Epoch 8/50\n",
            "150/150 - 17s - 112ms/step - loss: 0.5734 - sparse_categorical_accuracy: 0.6316 - val_loss: 1.0137 - val_sparse_categorical_accuracy: 0.5158 - learning_rate: 5.0000e-04\n",
            "Epoch 9/50\n",
            "150/150 - 19s - 129ms/step - loss: 0.5725 - sparse_categorical_accuracy: 0.6316 - val_loss: 0.9699 - val_sparse_categorical_accuracy: 0.5158 - learning_rate: 5.0000e-04\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "150/150 - 16s - 104ms/step - loss: 0.5725 - sparse_categorical_accuracy: 0.6327 - val_loss: 0.8977 - val_sparse_categorical_accuracy: 0.5158 - learning_rate: 5.0000e-04\n",
            "Epoch 11/50\n",
            "150/150 - 20s - 134ms/step - loss: 0.5722 - sparse_categorical_accuracy: 0.6320 - val_loss: 0.8370 - val_sparse_categorical_accuracy: 0.5158 - learning_rate: 2.5000e-04\n",
            "Epoch 12/50\n",
            "150/150 - 16s - 104ms/step - loss: 0.5719 - sparse_categorical_accuracy: 0.6329 - val_loss: 0.7419 - val_sparse_categorical_accuracy: 0.5158 - learning_rate: 2.5000e-04\n",
            "Epoch 12: early stopping\n",
            "Restoring model weights from the end of the best epoch: 4.\n",
            "\n",
            "Final Fold 3\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "150/150 - 27s - 180ms/step - loss: 0.7640 - sparse_categorical_accuracy: 0.5089 - val_loss: 0.7233 - val_sparse_categorical_accuracy: 0.5375 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "150/150 - 18s - 120ms/step - loss: 0.7316 - sparse_categorical_accuracy: 0.5169 - val_loss: 0.7231 - val_sparse_categorical_accuracy: 0.5375 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "150/150 - 16s - 107ms/step - loss: 0.7265 - sparse_categorical_accuracy: 0.5239 - val_loss: 0.7228 - val_sparse_categorical_accuracy: 0.5375 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "150/150 - 16s - 105ms/step - loss: 0.6283 - sparse_categorical_accuracy: 0.6002 - val_loss: 0.7303 - val_sparse_categorical_accuracy: 0.5292 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "150/150 - 15s - 103ms/step - loss: 0.5816 - sparse_categorical_accuracy: 0.6245 - val_loss: 0.7634 - val_sparse_categorical_accuracy: 0.5370 - learning_rate: 1.0000e-03\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "150/150 - 15s - 102ms/step - loss: 0.5802 - sparse_categorical_accuracy: 0.6215 - val_loss: 0.9290 - val_sparse_categorical_accuracy: 0.5405 - learning_rate: 1.0000e-03\n",
            "Epoch 7/50\n",
            "150/150 - 20s - 135ms/step - loss: 0.5748 - sparse_categorical_accuracy: 0.6261 - val_loss: 0.9475 - val_sparse_categorical_accuracy: 0.5407 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "150/150 - 20s - 136ms/step - loss: 0.5744 - sparse_categorical_accuracy: 0.6267 - val_loss: 1.0045 - val_sparse_categorical_accuracy: 0.5405 - learning_rate: 5.0000e-04\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "150/150 - 15s - 103ms/step - loss: 0.5738 - sparse_categorical_accuracy: 0.6267 - val_loss: 1.2806 - val_sparse_categorical_accuracy: 0.5405 - learning_rate: 5.0000e-04\n",
            "Epoch 10/50\n",
            "150/150 - 17s - 115ms/step - loss: 0.5730 - sparse_categorical_accuracy: 0.6282 - val_loss: 1.2168 - val_sparse_categorical_accuracy: 0.5405 - learning_rate: 2.5000e-04\n",
            "Epoch 11/50\n",
            "150/150 - 16s - 104ms/step - loss: 0.5729 - sparse_categorical_accuracy: 0.6306 - val_loss: 1.2948 - val_sparse_categorical_accuracy: 0.5405 - learning_rate: 2.5000e-04\n",
            "Epoch 11: early stopping\n",
            "Restoring model weights from the end of the best epoch: 3.\n",
            "\n",
            "Final Fold 4\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "150/150 - 29s - 195ms/step - loss: 0.7865 - sparse_categorical_accuracy: 0.5072 - val_loss: 0.7237 - val_sparse_categorical_accuracy: 0.5374 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "150/150 - 19s - 125ms/step - loss: 0.7306 - sparse_categorical_accuracy: 0.5209 - val_loss: 0.7235 - val_sparse_categorical_accuracy: 0.5374 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "150/150 - 15s - 101ms/step - loss: 0.6807 - sparse_categorical_accuracy: 0.5713 - val_loss: 0.7334 - val_sparse_categorical_accuracy: 0.5218 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "150/150 - 21s - 140ms/step - loss: 0.5881 - sparse_categorical_accuracy: 0.6197 - val_loss: 0.9577 - val_sparse_categorical_accuracy: 0.5399 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "150/150 - 16s - 109ms/step - loss: 0.5803 - sparse_categorical_accuracy: 0.6246 - val_loss: 0.9088 - val_sparse_categorical_accuracy: 0.5197 - learning_rate: 1.0000e-03\n",
            "Epoch 6/50\n",
            "150/150 - 16s - 104ms/step - loss: 0.5784 - sparse_categorical_accuracy: 0.6275 - val_loss: 0.7590 - val_sparse_categorical_accuracy: 0.5258 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "150/150 - 16s - 104ms/step - loss: 0.5765 - sparse_categorical_accuracy: 0.6270 - val_loss: 1.2041 - val_sparse_categorical_accuracy: 0.4456 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "150/150 - 16s - 104ms/step - loss: 0.5759 - sparse_categorical_accuracy: 0.6274 - val_loss: 1.3726 - val_sparse_categorical_accuracy: 0.4631 - learning_rate: 5.0000e-04\n",
            "Epoch 9/50\n",
            "150/150 - 21s - 139ms/step - loss: 0.5746 - sparse_categorical_accuracy: 0.6287 - val_loss: 1.0447 - val_sparse_categorical_accuracy: 0.4632 - learning_rate: 2.5000e-04\n",
            "Epoch 10/50\n",
            "150/150 - 20s - 133ms/step - loss: 0.5741 - sparse_categorical_accuracy: 0.6312 - val_loss: 1.0326 - val_sparse_categorical_accuracy: 0.5399 - learning_rate: 2.5000e-04\n",
            "Epoch 10: early stopping\n",
            "Restoring model weights from the end of the best epoch: 2.\n",
            "\n",
            "Final Fold 5\n",
            "Epoch 1/50\n",
            "150/150 - 28s - 185ms/step - loss: 0.7683 - sparse_categorical_accuracy: 0.5083 - val_loss: 0.7304 - val_sparse_categorical_accuracy: 0.5374 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "150/150 - 15s - 102ms/step - loss: 0.7307 - sparse_categorical_accuracy: 0.5172 - val_loss: 0.7233 - val_sparse_categorical_accuracy: 0.5374 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "150/150 - 21s - 141ms/step - loss: 0.7280 - sparse_categorical_accuracy: 0.5229 - val_loss: 0.7245 - val_sparse_categorical_accuracy: 0.5374 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "150/150 - 15s - 101ms/step - loss: 0.6490 - sparse_categorical_accuracy: 0.5946 - val_loss: 0.7237 - val_sparse_categorical_accuracy: 0.5367 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "150/150 - 21s - 140ms/step - loss: 0.5809 - sparse_categorical_accuracy: 0.6242 - val_loss: 1.0004 - val_sparse_categorical_accuracy: 0.5398 - learning_rate: 1.0000e-03\n",
            "Epoch 6/50\n",
            "150/150 - 17s - 112ms/step - loss: 0.5778 - sparse_categorical_accuracy: 0.6285 - val_loss: 0.9272 - val_sparse_categorical_accuracy: 0.5398 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "150/150 - 16s - 104ms/step - loss: 0.5764 - sparse_categorical_accuracy: 0.6289 - val_loss: 0.8790 - val_sparse_categorical_accuracy: 0.5398 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "150/150 - 30s - 200ms/step - loss: 0.5740 - sparse_categorical_accuracy: 0.6310 - val_loss: 1.2454 - val_sparse_categorical_accuracy: 0.5398 - learning_rate: 5.0000e-04\n",
            "Epoch 9/50\n",
            "150/150 - 30s - 202ms/step - loss: 0.5729 - sparse_categorical_accuracy: 0.6297 - val_loss: 1.1018 - val_sparse_categorical_accuracy: 0.5398 - learning_rate: 2.5000e-04\n",
            "Epoch 10/50\n",
            "150/150 - 17s - 112ms/step - loss: 0.5723 - sparse_categorical_accuracy: 0.6316 - val_loss: 1.1021 - val_sparse_categorical_accuracy: 0.5398 - learning_rate: 2.5000e-04\n",
            "Epoch 10: early stopping\n",
            "Restoring model weights from the end of the best epoch: 2.\n",
            "\n",
            "Final CV logloss: 0.7126322946163446 CV acc: 0.5381875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import numpy as np\n",
        "\n",
        "print(\"Computing SHAP with wrapped model...\")\n",
        "\n",
        "# Combine numeric + categorical inputs into one array for SHAP\n",
        "def model_wrapper(X):\n",
        "    # Split back into num and cat parts for model prediction\n",
        "    n_num = X_num_train.shape[1]\n",
        "    num = X[:, :n_num]\n",
        "    cat = X[:, n_num:].astype(np.int32)\n",
        "    return model({'num': num, 'cat': cat}).numpy()\n",
        "\n",
        "# Prepare background and explanation samples\n",
        "bg_n = min(200, len(X_num_train))\n",
        "bg_idx = np.random.choice(len(X_num_train), bg_n, replace=False)\n",
        "expl_idx = np.random.choice(len(X_num_train), min(200, len(X_num_train)), replace=False)\n",
        "\n",
        "# Concatenate numeric + categorical into one array\n",
        "X_bg = np.concatenate([X_num_train[bg_idx], X_cat_train[bg_idx]], axis=1)\n",
        "X_expl = np.concatenate([X_num_train[expl_idx], X_cat_train[expl_idx]], axis=1)\n",
        "\n",
        "# Create SHAP explainer on the wrapper\n",
        "explainer = shap.Explainer(model_wrapper, X_bg)\n",
        "\n",
        "# Compute SHAP values\n",
        "shap_values = explainer(X_expl)\n",
        "\n",
        "# Plot\n",
        "shap.summary_plot(shap_values, show=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "AdpnINZBezuq",
        "outputId": "59cf0a0a-00f8-4f35-cb3b-c6619a2b6550"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing SHAP with wrapped model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ExactExplainer explainer: 201it [01:04,  2.71it/s]\n",
            "/tmp/ipython-input-236506130.py:30: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
            "  shap.summary_plot(shap_values, show=True)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x310 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save final submission\n",
        "sub = sample_submission.copy()\n",
        "id_col = sub.columns[0]\n",
        "target_cols = sub.columns.tolist()[1:]\n",
        "\n",
        "# Ensure the submission DataFrame has the same index as the test data\n",
        "sub = pd.DataFrame({id_col: test[id_col]})\n",
        "\n",
        "if problem_type == 'multiclass':\n",
        "    # Assuming test_final predictions are in the same order as test dataframe\n",
        "    if len(target_cols) == test_final.shape[1]:\n",
        "        for i,col in enumerate(target_cols):\n",
        "            sub[col] = test_final[:, i]\n",
        "    else:\n",
        "        # If target columns in sample submission don't match prediction shape,\n",
        "        # assume it's a single target column and use argmax for multiclass\n",
        "        sub[target_cols[0]] = np.argmax(test_final, axis=1)\n",
        "else:\n",
        "    sub[target_cols[0]] = test_final\n",
        "out_name = 'submission_tf_full_complete.csv'\n",
        "sub.to_csv(out_name, index=False)\n",
        "print('Saved', out_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDsQfzOZitTp",
        "outputId": "f242db25-75b7-4c02-abfd-3d4d99d02a5a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission_tf_full_complete.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 🔍 Model Evaluation / Testing Cell\n",
        "# ============================================================\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, roc_auc_score, accuracy_score, log_loss\n",
        "\n",
        "print(\"🔍 Evaluating model performance...\")\n",
        "\n",
        "# ---------------------------\n",
        "# 1️⃣  Predict on validation or training data\n",
        "# ---------------------------\n",
        "# (Here we'll predict on all training data for quick inspection)\n",
        "y_pred = model.predict({'num': X_num_train, 'cat': X_cat_train}, batch_size=512, verbose=1)\n",
        "\n",
        "# ---------------------------\n",
        "# 2️⃣  Evaluate based on problem type\n",
        "# ---------------------------\n",
        "if problem_type == \"regression\":\n",
        "    rmse = mean_squared_error(y, y_pred, squared=False)\n",
        "    print(f\"✅ RMSE: {rmse:.5f}\")\n",
        "\n",
        "elif problem_type == \"binary\":\n",
        "    auc = roc_auc_score(y, y_pred)\n",
        "    acc = accuracy_score(y, (y_pred > 0.5).astype(int))\n",
        "    print(f\"✅ AUC: {auc:.5f} | ACC: {acc:.5f}\")\n",
        "\n",
        "elif problem_type == \"multiclass\":\n",
        "    y_pred_probs = y_pred\n",
        "    y_pred_labels = np.argmax(y_pred_probs, axis=1)\n",
        "    acc = accuracy_score(y, y_pred_labels)\n",
        "    loss = log_loss(y, y_pred_probs)\n",
        "    print(f\"✅ LogLoss: {loss:.5f} | ACC: {acc:.5f}\")\n",
        "\n",
        "# ---------------------------\n",
        "# 3️⃣  Optional: Predict on test set and preview\n",
        "# ---------------------------\n",
        "test_pred = model.predict({'num': X_num_test, 'cat': X_cat_test}, batch_size=512, verbose=1)\n",
        "\n",
        "print(\"\\n🧾 Test prediction preview:\")\n",
        "print(test_pred[:10].flatten() if test_pred.ndim == 2 else test_pred[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMy-kCM-l77U",
        "outputId": "6c3c029d-3d8e-4ded-a7e0-2076fceac403"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Evaluating model performance...\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step\n",
            "✅ LogLoss: 0.71301 | ACC: 0.53746\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step\n",
            "\n",
            "🧾 Test prediction preview:\n",
            "[0.55971295 0.4367438  0.00354327 0.55971295 0.43674383 0.00354327\n",
            " 0.5597129  0.4367439  0.00354327 0.5597128  0.43674394 0.00354327\n",
            " 0.5597127  0.43674397 0.00354327 0.55971265 0.43674394 0.00354327\n",
            " 0.55971265 0.4367441  0.00354326 0.55971265 0.43674412 0.00354326\n",
            " 0.5597125  0.4367442  0.00354326 0.5597125  0.43674424 0.00354326]\n"
          ]
        }
      ]
    }
  ]
}