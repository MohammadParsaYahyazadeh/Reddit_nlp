# 🧠 DEPI-R-3: Advanced Tabular Transformer for Kaggle Competition

An end-to-end **deep learning pipeline** for the [DEPI-R-3 Kaggle competition](https://www.kaggle.com/competitions/depi-r-3-competition-1/overview), built using **TensorFlow**, **Transformers**, and **modern tabular modeling techniques**.

---

## 🚀 Overview

This project develops an **advanced Transformer-based neural network** for tabular data, integrating:

- 🧩 **Categorical embeddings**
- ⚙️ **Transformer-style attention blocks**
- 🔁 **MLP (multi-layer perceptron) head**
- 🧮 **Leakage-safe target encoding**
- 🔍 **K-Fold cross-validation**
- 🎯 **Keras Tuner** for hyperparameter optimization
- 🔬 **SHAP explainability** for model interpretation

The goal is to achieve **strong performance and transparency** while maintaining generalization (avoiding overfitting).


